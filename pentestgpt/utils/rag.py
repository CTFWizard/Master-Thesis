from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import logging
import os


class Local_RAG:
    def __init__(self, rag_dir, logs_dir, challenge_name, chunk_size=None):
        # Logging init
        logger_name = __name__ + ".Local_RAG"
        self.logger = logging.getLogger(logger_name)

        ## FileHandler configuration
        log_file = os.path.join(logs_dir, challenge_name + ".raglog")
        file_handler = logging.FileHandler(log_file)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')
        file_handler.setFormatter(formatter)

        self.logger.addHandler(file_handler)
        self.logger.setLevel(logging.INFO)

        # Init
        self.rag_dir = rag_dir
        self.chunk_size = chunk_size
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.filenames, embeddings = self._create_chunk_embeddings(self.rag_dir)
        self.index = self._build_faiss_index(embeddings)
        self.logger.info("Initialized Local_RAG")


    def _create_chunk_embeddings(self, directory):
        self.chunk_identifiers = []  # To track filenames and chunk indices
        embeddings_list = []  # Temporary list to store embeddings
        
        for filename in os.listdir(directory):
            if filename.endswith(".md"):
                filepath = os.path.join(directory, filename)
                with open(filepath, 'r', encoding='utf-8') as file:
                    content = file.read()
                    
                    # If chunk_size is None or the content is smaller than the chunk_size, process the whole content
                    if self.chunk_size is None or len(content) <= self.chunk_size:
                        chunks = [content]  # Treat the entire content as a single chunk
                    else:
                        # Split the document into chunks and process each individually
                        chunks = [content[i:i + self.chunk_size] for i in range(0, len(content), self.chunk_size)]
                    
                    for i, chunk in enumerate(chunks):
                        embedding = self.model.encode(chunk, convert_to_tensor=False)
                        self.chunk_identifiers.append((filename, i))
                        embeddings_list.append(embedding)
        
        # Convert list of embeddings to a NumPy array
        self.embeddings = np.vstack(embeddings_list)
        return self.chunk_identifiers, self.embeddings


    def _build_faiss_index(self, embeddings):
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)  # Make sure embeddings are np.array
        index.add(embeddings)
        self.logger.info("Created FAISS index")
        return index

    def _semantic_search(self, user_prompt, n_results=5):
        query_embedding = self.model.encode([user_prompt], convert_to_tensor=False).reshape(1, -1)
        
        # Search the index for the closest chunk embeddings
        distances, indices = self.index.search(query_embedding, n_results)
        
        # Retrieve the corresponding chunk identifiers using the indices
        results = [(self.chunk_identifiers[i], distances[0][j]) for j, i in enumerate(indices[0])]
        return results
    
    def ask_rag(self, user_prompt, n_results=5):
        # Perform the semantic search to get the top chunk matches
        results = self._semantic_search(user_prompt, n_results=n_results)
        documents_with_scores = []

        if results:
            #self.logger.info(f"Local RAG received user prompt: {user_prompt}")
            for (filename, chunk_index), distance in results:
                file_path = os.path.join(self.rag_dir, filename)
                with open(file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                    
                    # Calculate the start and end index of the chunk within the content
                    start_index = chunk_index * self.chunk_size
                    end_index = start_index + self.chunk_size
                    
                    # Extract the specific chunk content
                    chunk_content = content[start_index:end_index]
                    documents_with_scores.append((filename, chunk_index, chunk_content, distance))

            if documents_with_scores:
                top_document, top_chunk, top_content, top_score = sorted(documents_with_scores, key=lambda x: x[3])[0]
                self.logger.info(f"- {top_document} [Chunk {top_chunk}] (Score: {top_score:.2f}) | prompt: {user_prompt} | rag-data: {top_content}")
                return top_content, top_score
        else:
            self.logger.warning(f"RAG found no matches for the prompt: {user_prompt}")
            return None

#if __name__ == "__main__":
#    from rich.console import Console
#    from pentestgpt.utils.cli_prompt_select import prompt_select, prompt_ask
#    chall = input("Please input challenge name: ")
#    rag = Local_RAG(rag_dir="./rag-data-iter2", logs_dir="./logs", challenge_name=chall, chunk_size=2500)
#    console = Console()
#    while True:
#        console.print(
#            "Your input: (End with <shift + right-arrow>)", style="bold green"
#        )
#        user_prompt = prompt_ask("> ", multiline=True)
#        rag_data, rag_score = rag.ask_rag(user_prompt)
#        print("The actual data from the file with the best score: " + str(rag_data))
#        print("What the score was: " + str(rag_score))
