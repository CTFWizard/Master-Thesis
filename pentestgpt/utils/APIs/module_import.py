import importlib
import dataclasses
import os, sys

from pentestgpt.utils.cli_prompt_select import prompt_select


module_mapping = {
    "gpt-4": {
        "config_name": "GPT4ConfigClass",
        "module_name": "chatgpt_api",
        "class_name": "ChatGPTAPI",
    },
    "gpt-4-turbo": {
        "config_name": "GPT4Turbo",
        "module_name": "chatgpt_api",
        "class_name": "ChatGPTAPI",
    },
    "gpt-3.5-turbo-16k": {
        "config_name": "GPT35Turbo16kConfigClass",
        "module_name": "chatgpt_api",
        "class_name": "ChatGPTAPI",
    },
    "gpt4all": {
        "config_name": "GPT4ALLConfigClass",
        "module_name": "gpt4all_api",
        "class_name": "GPT4ALLAPI",
    },
    "titan": {
        "config_name": "TitanConfigClass",
        "module_name": "titan_api",
        "class_name": "TitanAPI",
    },
    "azure-gpt-3.5": {
        "config_name": "AzureGPT35ConfigClass",
        "module_name": "azure_api",
        "class_name": "AzureGPTAPI",
    },
    "localAI-phi2": {
        "config_name": "LocalAIPhi2ConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "localAI-mistral": {
        "config_name": "LocalAIMistralConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "localAI-mixtral": {
        "config_name": "LocalAIMixtralConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "localAI-tinyllama": {
        "config_name": "LocalAITinyllamaConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "localAI-dolphin": {
        "config_name": "LocalAIDolphinConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "localAI-codellama": {
        "config_name": "LocalAICodellamaConfigClass",
        "module_name": "localai_api",
        "class_name": "LocalAIAPI"
    },
    "devAPI": {
        "config_name": "GPT4ConfigClass",
        "module_name": "devAPI",
        "class_name": "DummyAPI",
    }
}


@dataclasses.dataclass
class GPT4ConfigClass:
    model: str = "gpt-4"
    api_base: str = "https://api.openai.com/v1"
    # set up the openai key
    openai_key = os.getenv("OPENAI_KEY", None)
    if openai_key is None:
        print("Your OPENAI_KEY is not set. Please set it in the environment variable.")
    error_wait_time: float = 20
    is_debugging: bool = False


@dataclasses.dataclass
class GPT35Turbo16kConfigClass:
    model: str = "gpt-3.5-turbo-16k"
    api_base: str = "https://api.openai.com/v1"
    # set up the openai key
    openai_key = os.getenv("OPENAI_KEY", None)
    if openai_key is None:
        print("Your OPENAI_KEY is not set. Please set it in the environment variable.")
    error_wait_time: float = 20
    is_debugging: bool = False


@dataclasses.dataclass
class GPT4Turbo:
    model: str = "gpt-4-1106-preview"
    api_base: str = "https://api.openai.com/v1"
    # set up the openai key
    openai_key = os.getenv("OPENAI_KEY", None)
    if openai_key is None:
        print("Your OPENAI_KEY is not set. Please set it in the environment variable.")
    error_wait_time: float = 20
    is_debugging: bool = False


@dataclasses.dataclass
class GPT4ALLConfigClass:
    model: str = "mistral-7b-openorca.Q4_0.gguf"


@dataclasses.dataclass
class TitanConfigClass:
    model: str = "amazon.titan-tg1-large"


@dataclasses.dataclass
class AzureGPT35ConfigClass:
    model: str = "gpt-35-turbo"
    api_type: str = "azure"
    api_base: str = "https://docs-test-001.openai.azure.com/"
    openai_key = os.getenv("OPENAI_KEY", None)
    if openai_key is None:
        print("Your OPENAI_KEY is not set. Please set it in the environment variable.")
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAIPhi2ConfigClass:
    model: str = "phi-2"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAIMistralConfigClass:
    model: str = "mistral-openorca"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAIMixtralConfigClass:
    model: str = "mixtral-instruct"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAITinyllamaConfigClass:
    model: str = "tinyllama-chat"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAIDolphinConfigClass:
    model: str = "dolphin-2.5-mixtral-8x7b"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

@dataclasses.dataclass
class LocalAICodellamaConfigClass:
    model: str = "codellama-7b-gguf"
    api_base = "http://localhost:8080/v1"
    error_wait_time: float = 20
    is_debugging: bool = False

def dynamic_import(module_name, log_dir, use_langfuse_logging=False) -> object:
    if module_name in module_mapping:
        module_config_name = module_mapping[module_name]["config_name"]
        module_import_name = module_mapping[module_name]["module_name"]
        class_name = module_mapping[module_name]["class_name"]
        module_config = getattr(sys.modules[__name__], module_config_name)
        module_config.log_dir = log_dir

        # import the module
        LLM_module = importlib.import_module(
            "pentestgpt.utils.APIs." + module_import_name
        )
        LLM_class = getattr(LLM_module, class_name)
        # initialize the class
        LLM_class_initialized = LLM_class(
            module_config, use_langfuse_logging=use_langfuse_logging
        )

        return LLM_class_initialized

    else:
        print(
            "Module not found: "
            + module_name
            + ". Falling back to use the default gpt-3.5-turbo-16k"
        )
        # fall back to gpt-3.5-turbo-16k
        LLM_class_initialized = dynamic_import("gpt-3.5-turbo-16k", log_dir)
        return LLM_class_initialized


if __name__ == "__main__":
    # a quick local test
    # load gpt4
    gpt4 = dynamic_import("devAPI", "logs")
    init_response, conversation_id = gpt4.send_new_message("hi")
    response = gpt4.send_message("Hello, world!", conversation_id)
    print(response)
